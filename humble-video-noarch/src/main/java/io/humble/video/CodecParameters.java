/* ----------------------------------------------------------------------------
 * This file was automatically generated by SWIG (http://www.swig.org).
 * Version 2.0.6
 *
 * Do not make changes to this file unless you know what you are doing--modify
 * the SWIG interface file instead.
 * ----------------------------------------------------------------------------- */

package io.humble.video;
import io.humble.ferry.*;
public class CodecParameters extends RefCounted {
  // JNIHelper.swg: Start generated code
  // >>>>>>>>>>>>>>>>>>>>>>>>>>>
  /**
   * This method is only here to use some references and remove
   * a Eclipse compiler warning.
   */
  @SuppressWarnings("unused")
  private void noop()
  {
    Buffer.make(null, 1);
  }
   
  private volatile long swigCPtr;

  /**
   * Internal Only.
   */
  protected CodecParameters(long cPtr, boolean cMemoryOwn) {
    super(VideoJNI.CodecParameters_SWIGUpcast(cPtr), cMemoryOwn);
    swigCPtr = cPtr;
  }
  
  /**
   * Internal Only.
   */
  protected CodecParameters(long cPtr, boolean cMemoryOwn,
      java.util.concurrent.atomic.AtomicLong ref)
  {
    super(VideoJNI.CodecParameters_SWIGUpcast(cPtr),
     cMemoryOwn, ref);
    swigCPtr = cPtr;
  }
    
  /**
   * Internal Only.  Not part of public API.
   *
   * Get the raw value of the native object that obj is proxying for.
   *   
   * @param obj The java proxy object for a native object.
   * @return The raw pointer obj is proxying for.
   */
  protected static long getCPtr(CodecParameters obj) {
    if (obj == null) return 0;
    return obj.getMyCPtr();
  }

  /**
   * Internal Only.  Not part of public API.
   *
   * Get the raw value of the native object that we're proxying for.
   *   
   * @return The raw pointer we're proxying for.
   */  
  protected long getMyCPtr() {
    if (swigCPtr == 0) throw new IllegalStateException("underlying native object already deleted");
    return swigCPtr;
  }
  
  /**
   * Create a new CodecParameters object that is actually referring to the
   * exact same underlying native object.
   *
   * @return the new Java object.
   */
  @Override
  public CodecParameters copyReference() {
    if (swigCPtr == 0)
      return null;
    else
      return new CodecParameters(swigCPtr, swigCMemOwn, getJavaRefCount());
  }

  /**
   * Compares two values, returning true if the underlying objects in native code are the same object.
   *
   * That means you can have two different Java objects, but when you do a comparison, you'll find out
   * they are the EXACT same object.
   *
   * @return True if the underlying native object is the same.  False otherwise.
   */
  public boolean equals(Object obj) {
    boolean equal = false;
    if (obj instanceof CodecParameters)
      equal = (((CodecParameters)obj).swigCPtr == this.swigCPtr);
    return equal;
  }
  
  /**
   * Get a hashable value for this object.
   *
   * @return the hashable value.
   */
  public int hashCode() {
     return (int)swigCPtr;
  }
  
  // <<<<<<<<<<<<<<<<<<<<<<<<<<<
  // JNIHelper.swg: End generated code
  
/**
 * General type of the encoded data.
 */
  public MediaDescriptor.Type getType() {
    return MediaDescriptor.Type.swigToEnum(VideoJNI.CodecParameters_getType(swigCPtr, this));
  }

/**
 * Specific type of the encoded data (the codec used).
 */
  public Codec.ID getID() {
    return Codec.ID.swigToEnum(VideoJNI.CodecParameters_getID(swigCPtr, this));
  }

/**
 * Additional information about the codec (corresponds to the AVI FOURCC).
 */
  public long getTag() {
    return VideoJNI.CodecParameters_getTag(swigCPtr, this);
  }

/**
 * Extra binary data needed for initializing the decoder, codec-dependent.<br>
 * <br>
 * Must be allocated with av_malloc() and will be freed by<br>
 * avcodec_parameters_free(). The allocated size of extradata must be at<br>
 * least extradata_size + AV_INPUT_BUFFER_PADDING_SIZE, with the padding<br>
 * bytes zeroed.<br>
 * <br>
 * Size of the extradata content in bytes.<br>
 * <br>
 * Get the Pixel Format, or PixelFormat.PIX_FMT_NONE if the parameter #getType()<br>
 * is not MediaDescriptor.MEDIA_VIDEO.<br>
 * <br>
 * @return the pixel format.
 */
  public PixelFormat.Type getPixelFormat() {
    return PixelFormat.Type.swigToEnum(VideoJNI.CodecParameters_getPixelFormat(swigCPtr, this));
  }

/**
 * Sets the pixel format (it is up to the caller<br>
 * to ensure that #getType() is MediaDescriptor.MEDIA_VIDEO. Otherwise<br>
 * behaviour is undefined.<br>
 * <br>
 * @param format Pixel Format to set format to.<br>
 * @see #getPixelFormat()
 */
  public void setPixelFormat(PixelFormat.Type format) {
    VideoJNI.CodecParameters_setPixelFormat(swigCPtr, this, format.swigValue());
  }

/**
 * Get the Audio Format, or AudioFormat.SAMPLE_FMT_NONE if the parameter #getType()<br>
 * is not MediaDescriptor.MEDIA_AUDIO.<br>
 * <br>
 * @return the audio format.
 */
  public AudioFormat.Type getAudioFormat() {
    return AudioFormat.Type.swigToEnum(VideoJNI.CodecParameters_getAudioFormat(swigCPtr, this));
  }

/**
 * Sets the audio format (it is up to the caller<br>
 * to ensure that #getType() is MediaDescriptor.MEDIA_AUDIO. Otherwise<br>
 * behaviour is undefined.<br>
 * <br>
 * @param format Audio Format to set format to.<br>
 * @see #getAudioFormat()
 */
  public void setAudioFormat(AudioFormat.Type format) {
    VideoJNI.CodecParameters_setAudioFormat(swigCPtr, this, format.swigValue());
  }

/**
 * Get the average bit-rate (in bits per second) of encoded data.<br>
 * @return the bit rate.
 */
  public long getBitRate() {
    return VideoJNI.CodecParameters_getBitRate(swigCPtr, this);
  }

/**
 * Set the bit-rate (in bits per second) of encoded data.<br>
 * @param bit_rate the bit rate.
 */
  public void setBitRate(long bit_rate) {
    VideoJNI.CodecParameters_setBitRate(swigCPtr, this, bit_rate);
  }

/**
 * Get the number of bits per sample in the codedwords.<br>
 * <p><br>
 * This is basically the bitrate per sample. It is mandatory for a bunch of<br>
 * formats to actually decode them. It's the number of bits for one sample in<br>
 * the actual coded bitstream.<br>
 * </p><br>
 * <p><br>
 * This could be for example 4 for ADPCM<br>
 * For PCM formats this matches bits_per_raw_sample<br>
 * </p><br>
 * <p><br>
 * Can be 0.<br>
 * </p>
 */
  public long getBitsPerCodedSample() {
    return VideoJNI.CodecParameters_getBitsPerCodedSample(swigCPtr, this);
  }

/**
 * Set the bits per coded sample.<br>
 * @param bitsPerCodedSample bits per coded sample.<br>
 * @see #getBitsPerCodedSample()
 */
  public void setBitsPerCodedSample(long bitsPerCodedSample) {
    VideoJNI.CodecParameters_setBitsPerCodedSample(swigCPtr, this, bitsPerCodedSample);
  }

/**
 * This is the number of valid bits in each output sample.<br>
 *         * <p><br>
 * If the sample format has more bits, the least significant bits are additional<br>
 * padding bits, which are always 0. Use right shifts to reduce the sample<br>
 * to its actual size. For example, audio formats with 24 bit samples will<br>
 * have bits_per_raw_sample set to 24, and format set to AudioFormat.SAMPLE_FMT_S32.<br>
 * To get the original sample use "(int32_t)sample >> 8"."<br>
 * </p><br>
 * <p><br>
 * For ADPCM this might be 12 or 16 or similar<br>
 * </p><br>
 * <p><br>
 * Can be 0.<br>
 * </p>
 */
  public long getBitsPerRawSample() {
    return VideoJNI.CodecParameters_getBitsPerRawSample(swigCPtr, this);
  }

/**
 * Sets the bits per raw sample.<br>
 * @param bitsPerRawSample bits per raw sample.<br>
 * @see #getBitsPerRawSample()
 */
  public void setBitsPerRawSample(long bitsPerRawSample) {
    VideoJNI.CodecParameters_setBitsPerRawSample(swigCPtr, this, bitsPerRawSample);
  }

/**
 * Codec-specific bitstream restrictions that the stream conforms to.<br>
 * @return the profile.
 */
  public long getProfile() {
    return VideoJNI.CodecParameters_getProfile(swigCPtr, this);
  }

/**
 * @see getProfile()
 */
  public void setProfile(long profile) {
    VideoJNI.CodecParameters_setProfile(swigCPtr, this, profile);
  }

/**
 * Codec-specific bitstream restriction level that the stream conforms to.<br>
 * @return the level.
 */
  public long getLevel() {
    return VideoJNI.CodecParameters_getLevel(swigCPtr, this);
  }

/**
 * See #getLevel()
 */
  public void setLevel(long level) {
    VideoJNI.CodecParameters_setLevel(swigCPtr, this, level);
  }

/**
 * Get the picture width in pixels. Video only.
 */
  public int getWidth() {
    return VideoJNI.CodecParameters_getWidth(swigCPtr, this);
  }

/**
 * @see #getWidth()
 */
  public void setWidth(int width) {
    VideoJNI.CodecParameters_setWidth(swigCPtr, this, width);
  }

/**
 * Get the picture height in pixels. Video only.
 */
  public int getHeight() {
    return VideoJNI.CodecParameters_getHeight(swigCPtr, this);
  }

/**
 * @see #getHeight()
 */
  public void setHeight(int height) {
    VideoJNI.CodecParameters_setHeight(swigCPtr, this, height);
  }

/**
 *  The aspect ratio (width / height) which a single pixel<br>
 * should have when displayed. Video only.<br>
 * <br>
 * When the aspect ratio is unknown / undefined, the numerator should be<br>
 * set to 0 (the denominator may have any value).
 */
  public Rational getSampleAspectRatio() {
    long cPtr = VideoJNI.CodecParameters_getSampleAspectRatio(swigCPtr, this);
    return (cPtr == 0) ? null : new Rational(cPtr, false);
  }

/**
 * See #getSampleAspectRatio()
 */
  public void setSampleAspectRatio(Rational newValue) {
    VideoJNI.CodecParameters_setSampleAspectRatio(swigCPtr, this, Rational.getCPtr(newValue), newValue);
  }

/**
 * Sets the field order. Video only.
 */
  public PixelFormat.FieldOrder getFieldOrder() {
    return PixelFormat.FieldOrder.swigToEnum(VideoJNI.CodecParameters_getFieldOrder(swigCPtr, this));
  }

/**
 * @see getFieldOrder()
 */
  public void setFieldOrder(PixelFormat.FieldOrder order) {
    VideoJNI.CodecParameters_setFieldOrder(swigCPtr, this, order.swigValue());
  }

/**
 * Get the color range. Video only.
 */
  public PixelFormat.ColorRange getColorRange() {
    return PixelFormat.ColorRange.swigToEnum(VideoJNI.CodecParameters_getColorRange(swigCPtr, this));
  }

/**
 * @see #getColorRange()
 */
  public void setColorRange(PixelFormat.ColorRange range) {
    VideoJNI.CodecParameters_setColorRange(swigCPtr, this, range.swigValue());
  }

/**
 * Get the color primaries. Video only.
 */
  public PixelFormat.ColorPrimaries getColorPrimaries() {
    return PixelFormat.ColorPrimaries.swigToEnum(VideoJNI.CodecParameters_getColorPrimaries(swigCPtr, this));
  }

/**
 * @see #getColorPrimaries()
 */
  public void setColorPrimaries(PixelFormat.ColorPrimaries primaries) {
    VideoJNI.CodecParameters_setColorPrimaries(swigCPtr, this, primaries.swigValue());
  }

/**
 * Get the color transfer characteristic. Video only.
 */
  public PixelFormat.ColorTransferCharacteristic getColorTransferCharacteristic() {
    return PixelFormat.ColorTransferCharacteristic.swigToEnum(VideoJNI.CodecParameters_getColorTransferCharacteristic(swigCPtr, this));
  }

/**
 * See #getColorTransferCharacteristic()
 */
  public void setColorTransferCharacteristic(PixelFormat.ColorTransferCharacteristic trc) {
    VideoJNI.CodecParameters_setColorTransferCharacteristic(swigCPtr, this, trc.swigValue());
  }

/**
 * Get the color space. Video only.
 */
  public PixelFormat.ColorSpace getColorSpace() {
    return PixelFormat.ColorSpace.swigToEnum(VideoJNI.CodecParameters_getColorSpace(swigCPtr, this));
  }

/**
 * @see #getColorSpace()
 */
  public void setColorSpace(PixelFormat.ColorSpace space) {
    VideoJNI.CodecParameters_setColorSpace(swigCPtr, this, space.swigValue());
  }

/**
 * Get the chroma location. Video only.<br>
 * @see PixelFormat.ChromaLocation
 */
  public PixelFormat.ChromaLocation getChromaLocation() {
    return PixelFormat.ChromaLocation.swigToEnum(VideoJNI.CodecParameters_getChromaLocation(swigCPtr, this));
  }

/**
 * @see #getChromaLocation()
 */
  public void setChromaLocation(PixelFormat.ChromaLocation loc) {
    VideoJNI.CodecParameters_setChromaLocation(swigCPtr, this, loc.swigValue());
  }

/**
 * Number of delayed frames. Video only.
 */
  public int getVideoDelay() {
    return VideoJNI.CodecParameters_getVideoDelay(swigCPtr, this);
  }

/**
 * @see #getVideoDelay()
 */
  public void setVideoDelay(int delay) {
    VideoJNI.CodecParameters_setVideoDelay(swigCPtr, this, delay);
  }

/**
 * The channel layout bitmask. Audio only. May be 0 if the channel layout is<br>
 * unknown or unspecified, otherwise the number of bits set must be equal to<br>
 * the channels field.
 */
  public java.math.BigInteger getChannelLayout() {
    return VideoJNI.CodecParameters_getChannelLayout(swigCPtr, this);
  }

/**
 * @see #getChannelLayout()
 */
  public void setChannelLayout(java.math.BigInteger layout) {
    VideoJNI.CodecParameters_setChannelLayout(swigCPtr, this, layout);
  }

/**
 * The number of audio channels. Audio only.
 */
  public int getChannels() {
    return VideoJNI.CodecParameters_getChannels(swigCPtr, this);
  }

/**
 * @see #getChannels()
 */
  public void setChannels(int channels) {
    VideoJNI.CodecParameters_setChannels(swigCPtr, this, channels);
  }

/**
 * The number of audio samples per second. Audio only.
 */
  public int getSampleRate() {
    return VideoJNI.CodecParameters_getSampleRate(swigCPtr, this);
  }

/**
 * @see #getSampleRate()
 */
  public void setSampleRate(int rate) {
    VideoJNI.CodecParameters_setSampleRate(swigCPtr, this, rate);
  }

/**
 * The number of bytes per coded audio frame, required by some<br>
 * formats. Audio only.<br>
 * <br>
 * Corresponds to nBlockAlign in WAVEFORMATEX.
 */
  public int getBlockAlign() {
    return VideoJNI.CodecParameters_getBlockAlign(swigCPtr, this);
  }

  public void setBlockAlign(int align) {
    VideoJNI.CodecParameters_setBlockAlign(swigCPtr, this, align);
  }

/**
 * Audio frame size, if known. Audio only. Required by some formats to be static.
 */
  public int getFrameSize() {
    return VideoJNI.CodecParameters_getFrameSize(swigCPtr, this);
  }

/**
 * @see #getFrameSize()
 */
  public void setFrameSize(int size) {
    VideoJNI.CodecParameters_setFrameSize(swigCPtr, this, size);
  }

/**
 * The amount of padding (in samples) inserted by the encoder at<br>
 * the beginning of the audio. Audio only. I.e. this number of leading decoded samples<br>
 * must be discarded by the caller to get the original audio without leading<br>
 * padding.
 */
  public int getInitialPadding() {
    return VideoJNI.CodecParameters_getInitialPadding(swigCPtr, this);
  }

/**
 * @see #getInitialPadding()
 */
  public void setInitialPadding(int pad) {
    VideoJNI.CodecParameters_setInitialPadding(swigCPtr, this, pad);
  }

/**
 * The amount of padding (in samples) appended by the encoder to<br>
 * the end of the audio. Audio only. I.e. this number of decoded samples must be<br>
 * discarded by the caller from the end of the stream to get the original<br>
 * audio without any trailing padding.
 */
  public int getTrailingPadding() {
    return VideoJNI.CodecParameters_getTrailingPadding(swigCPtr, this);
  }

/**
 * @see #getTrailingPadding()
 */
  public void setTrailingPadding(int pad) {
    VideoJNI.CodecParameters_setTrailingPadding(swigCPtr, this, pad);
  }

/**
 * Number of samples to skip after a discontinuity. Audio only.
 */
  public int getSeekPreroll() {
    return VideoJNI.CodecParameters_getSeekPreroll(swigCPtr, this);
  }

/**
 * @see #getSeekPreroll()
 */
  public void setSeekPreroll(int preroll) {
    VideoJNI.CodecParameters_setSeekPreroll(swigCPtr, this, preroll);
  }

}
